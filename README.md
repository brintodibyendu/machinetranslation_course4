# machinetranslation_course4
Recently I have been doing a Coursera natural language specialization course. I am currently in the seq2seq course where I am learning about the seq2seq model, attention, transformer, state of art transformer model, including T5, and BERT. They covered all intrinsic topics about beam search, and the minimum bias was reduced significantly.

In this repository, I am uploading the assignment code as well as the ungraded lab codes. I noticed due to changes in the course, there are significant changes with the previous course content and lab. So this repository will be highly helpful for new learners. 
